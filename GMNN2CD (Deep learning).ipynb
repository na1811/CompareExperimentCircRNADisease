{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1290530f",
   "metadata": {},
   "source": [
    "## GMNN2CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3a6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sortscore\n",
    "from MakeSimilarityMatrix import MakeSimilarityMatrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from models import GraphConv, AE, LP\n",
    "# from utils import *\n",
    "# from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3dde24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    no_cuda=False,\n",
    "    seed=1,\n",
    "    epochs=500,\n",
    "    lr=0.01,\n",
    "    weight_decay=1e-5,\n",
    "    hidden=256,\n",
    "    alpha=0.8,\n",
    "    data=1\n",
    ")\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be4ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed,cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "set_seed(args.seed, args.cuda)\n",
    "# gdi, ldi, rnafeat, gl, gd = load_data(args.data, args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87c86ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNNq, self).__init__()\n",
    "        self.gnnql = AE(rnafeat.shape[1], 256, args.hidden)\n",
    "        self.gnnqd = AE(gdi.shape[0], 256, args.hidden)\n",
    "\n",
    "    def forward(self, xl0, xd0):\n",
    "        hl, stdl, xl = self.gnnql(gl, xl0)\n",
    "        hd, stdd, xd = self.gnnqd(gd, xd0)\n",
    "        return hl, stdl, xl, hd, stdd, xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a143ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNNp, self).__init__()\n",
    "        self.gnnpl = LP(args.hidden, ldi.shape[1])\n",
    "        self.gnnpd = LP(args.hidden, ldi.shape[0])\n",
    "\n",
    "    def forward(self, y0):\n",
    "        yl, zl = self.gnnpl(gl, y0)\n",
    "        yd, zd = self.gnnpd(gd, y0.t())\n",
    "        return yl, zl, yd, zd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cacbee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1, 5-fold CV\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92f27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GIP(circrna_disease_matrix):\n",
    "    make_sim_matrix = MakeSimilarityMatrix(circrna_disease_matrix)\n",
    "    return make_sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e84f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborhood(feat, k):\n",
    "    # print(\"This is neighborhood...\")\n",
    "    # compute C\n",
    "    featprod = np.dot(feat.T, feat)\n",
    "    smat = np.tile(np.diag(featprod), (feat.shape[1], 1))\n",
    "    dmat = smat + smat.T - 2 * featprod\n",
    "    dsort = np.argsort(dmat)[:, 1:k + 1]\n",
    "    C = np.zeros((feat.shape[1], feat.shape[1]))\n",
    "    for i in range(feat.shape[1]):\n",
    "        for j in dsort[i]:\n",
    "            C[i, j] = 1.0\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ecb8f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(wmat):\n",
    "    # print(\"This is normalized...\")\n",
    "    deg = np.diag(np.sum(wmat, axis=0))\n",
    "    degpow = np.power(deg, -0.5)\n",
    "    degpow[np.isinf(degpow)] = 0\n",
    "    W = np.dot(np.dot(degpow, wmat), degpow)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9388b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_adj(feat):\n",
    "    # print(\"This is norm_adj...\")\n",
    "    C = neighborhood(feat.T, k=10)\n",
    "    norm_adj = normalized(C.T * C + np.eye(C.shape[0]))\n",
    "    g = torch.from_numpy(norm_adj).float()\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d109221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(rel_matrix, cuda):\n",
    "    make_sim_matrix = GIP(rel_matrix)\n",
    "    # circ_gipsim_matrix, dis_gipsim_matrix = make_sim_matrix.circsimmatrix, make_sim_matrix.dissimmatrix\n",
    "    rnafeat, gdi = make_sim_matrix.circsimmatrix, make_sim_matrix.dissimmatrix\n",
    "    ldi = rel_matrix.copy()\n",
    "\n",
    "    rnafeat = minmax_scale(rnafeat, axis=0)\n",
    "    gdit = torch.from_numpy(gdi).float()\n",
    "    ldit = torch.from_numpy(ldi).float()\n",
    "    rnafeatorch = torch.from_numpy(rnafeat).float()\n",
    "    gl = norm_adj(rnafeat)\n",
    "    gd = norm_adj(gdi.T)\n",
    "    if cuda:\n",
    "        gdit = gdit.cuda()\n",
    "        ldit = ldit.cuda()\n",
    "        rnafeatorch = rnafeatorch.cuda()\n",
    "        gl = gl.cuda()\n",
    "        gd = gd.cuda()\n",
    "\n",
    "    return gdit, ldit, rnafeatorch, gl, gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14c39d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(output, target, msg, n_nodes, mu, logvar):\n",
    "    if msg == 'disease':\n",
    "        cost = F.binary_cross_entropy(output, target)\n",
    "    else:\n",
    "        cost = F.mse_loss(output, target)\n",
    "\n",
    "    KL = -0.5 / n_nodes * torch.mean(torch.sum(\n",
    "        1 + 2 * logvar - mu.pow(2) - logvar.exp().pow(2), 1))\n",
    "    return cost + KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e36b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gnnq, gnnp, xl0, xd0, y0, epoch, alpha, i):\n",
    "    losspl1 = []\n",
    "    losspd1 = []\n",
    "    lossp1 = []\n",
    "    lossq1 = []\n",
    "    beta0 = 1.0\n",
    "    gamma0 = 1.0\n",
    "    optp = torch.optim.Adam(gnnp.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    optq = torch.optim.Adam(gnnq.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "    for e in range(epoch):\n",
    "        gnnq.train()\n",
    "\n",
    "        gnnq.train()\n",
    "        hl, stdl, xl, hd, stdd, xd = gnnq(xl0, xd0)\n",
    "        lossql = criterion(xl, xl0,\n",
    "                           \"lncrna\", gl.shape[0], hl, stdl)\n",
    "        lossqd = criterion(xd, xd0,\n",
    "                           \"disease\", gd.shape[0], hd, stdd)\n",
    "        lossq = alpha * lossql + (1 - alpha) * lossqd + beta0 * e * F.mse_loss(\n",
    "            torch.mm(hl, hd.t()), y0) / epoch\n",
    "        optq.zero_grad()\n",
    "        lossq1.append(lossq.item())\n",
    "        lossq.backward()\n",
    "        optq.step()\n",
    "        gnnq.eval()\n",
    "        with torch.no_grad():\n",
    "            hl, _, _, hd, _, _ = gnnq(xl0, xd0)\n",
    "\n",
    "        gnnp.train()\n",
    "        yl, zl, yd, zd = gnnp(y0)\n",
    "        losspl = F.binary_cross_entropy(yl, y0) + gamma0 * e * F.mse_loss(zl, hl) / epoch\n",
    "        losspd = F.binary_cross_entropy(yd, y0.t()) + gamma0 * e * F.mse_loss(zd, hd) / epoch\n",
    "        lossp = alpha * losspl + (1 - alpha) * losspd\n",
    "        losspl1.append(losspl.item())\n",
    "        losspd1.append(losspd.item())\n",
    "        lossp1.append(lossp.item())\n",
    "        optp.zero_grad()\n",
    "        lossp.backward()\n",
    "        optp.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            yl, _, yd, _ = gnnp(y0)\n",
    "        # r = pd.DataFrame(lossp1)\n",
    "        # r.to_csv('./output/lossp1{}.csv'.format(i))\n",
    "        # r1 = pd.DataFrame(lossq1)\n",
    "        # r.to_csv('./output/lossq1{}.csv'.format(i))\n",
    "        # r = pd.DataFrame(losspd1)\n",
    "        # r.to_csv('./output/losspd1{}.csv'.format(i))\n",
    "        # r = pd.DataFrame(losspl1)\n",
    "        # r.to_csv('./output/losspl1{}.csv'.format(i))\n",
    "    return alpha * yl + (1 - alpha) * yd.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "932dd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    " with h5py.File('./Data/circRNA_cancer/circRNA_cancer.h5', 'r') as hf:\n",
    "        circrna_disease_matrix = hf['infor'][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c63c6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(circrna_disease_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27d00749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   52   53   54   55  \\\n",
       "0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    56   57   58   59   60   61  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21971214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "647.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "342523fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tuple = (np.where(circrna_disease_matrix == 1))\n",
    "one_list = list(zip(index_tuple[0], index_tuple[1]))\n",
    "random.shuffle(one_list)\n",
    "split = math.ceil(len(one_list) / 5)\n",
    "\n",
    "all_tpr = []\n",
    "all_fpr = []\n",
    "all_recall = []\n",
    "all_precision = []\n",
    "all_accuracy = []\n",
    "all_F1 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e5ac799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7248\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7248\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7248\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7248\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7248\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data\n"
     ]
    }
   ],
   "source": [
    " # 5-fold start\n",
    "for i in range(0, len(one_list), split):\n",
    "    test_index = one_list[i:i + split]\n",
    "    new_circrna_disease_matrix = circrna_disease_matrix.copy()\n",
    "\n",
    "    for index in test_index:\n",
    "        new_circrna_disease_matrix[index[0], index[1]] = 0\n",
    "    roc_circrna_disease_matrix = new_circrna_disease_matrix + circrna_disease_matrix\n",
    "    rel_matrix = new_circrna_disease_matrix\n",
    "    circnum = rel_matrix.shape[0]\n",
    "    disnum = rel_matrix.shape[1]\n",
    "\n",
    "    gdi, ldi, rnafeat, gl, gd = load_data(rel_matrix, args.cuda)\n",
    "    # print(\"gdi\",gdi)\n",
    "    # gdi = torch.tensor(gdi)\n",
    "    # ldi = torch.tensor(ldi)\n",
    "    # rnafeat = torch.tensor(rnafeat)\n",
    "    # gl = torch.tensor(gl)\n",
    "    # gd = torch.tensor(gd)\n",
    "\n",
    "    print(\"load_data\")\n",
    "\n",
    "    gnnq = GNNq()\n",
    "    gnnp = GNNp()\n",
    "    if args.cuda:\n",
    "        gnnq = gnnq.cuda()\n",
    "        gnnp = gnnp.cuda()\n",
    "\n",
    "    rel_matrix_tensor = torch.tensor(np.array(rel_matrix).astype(np.float32))\n",
    "    train(gnnq, gnnp, rnafeat, gdi.t(), rel_matrix_tensor, args.epochs, 0.8, i)\n",
    "    gnnq.eval()\n",
    "    gnnp.eval()\n",
    "    yli, _, ydi, _ = gnnp(rel_matrix_tensor)\n",
    "    resi = args.alpha * yli + (1 - args.alpha) * ydi.t()\n",
    "    if args.cuda:\n",
    "        ymat = resi.cpu().detach().numpy()\n",
    "    else:\n",
    "        ymat = resi.detach().numpy()\n",
    "\n",
    "    S = ymat\n",
    "    prediction_matrix = S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1982f9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008741</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.688781</td>\n",
       "      <td>0.025336</td>\n",
       "      <td>0.023262</td>\n",
       "      <td>0.102780</td>\n",
       "      <td>0.020752</td>\n",
       "      <td>0.033187</td>\n",
       "      <td>0.102780</td>\n",
       "      <td>0.006569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.102851</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.007052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>0.029653</td>\n",
       "      <td>0.101537</td>\n",
       "      <td>0.024451</td>\n",
       "      <td>0.035338</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.101543</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>0.006179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.151338</td>\n",
       "      <td>0.027289</td>\n",
       "      <td>0.257260</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>0.386028</td>\n",
       "      <td>0.068080</td>\n",
       "      <td>0.119396</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050460</td>\n",
       "      <td>0.145669</td>\n",
       "      <td>0.026675</td>\n",
       "      <td>0.026124</td>\n",
       "      <td>0.119680</td>\n",
       "      <td>0.029328</td>\n",
       "      <td>0.138876</td>\n",
       "      <td>0.028094</td>\n",
       "      <td>0.355439</td>\n",
       "      <td>0.152298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.020329</td>\n",
       "      <td>0.022626</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>0.100265</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.030677</td>\n",
       "      <td>0.100267</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.100271</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.003972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.403434</td>\n",
       "      <td>0.402115</td>\n",
       "      <td>0.403057</td>\n",
       "      <td>0.418408</td>\n",
       "      <td>0.402515</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.402329</td>\n",
       "      <td>0.428596</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.401994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404433</td>\n",
       "      <td>0.402025</td>\n",
       "      <td>0.402043</td>\n",
       "      <td>0.402043</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.402897</td>\n",
       "      <td>0.403434</td>\n",
       "      <td>0.402274</td>\n",
       "      <td>0.401799</td>\n",
       "      <td>0.402766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.403437</td>\n",
       "      <td>0.402116</td>\n",
       "      <td>0.403067</td>\n",
       "      <td>0.418416</td>\n",
       "      <td>0.402523</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.402335</td>\n",
       "      <td>0.428610</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.401995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404436</td>\n",
       "      <td>0.402027</td>\n",
       "      <td>0.402044</td>\n",
       "      <td>0.402044</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.402898</td>\n",
       "      <td>0.403437</td>\n",
       "      <td>0.402275</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.008855</td>\n",
       "      <td>0.025414</td>\n",
       "      <td>0.013355</td>\n",
       "      <td>0.100673</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.035580</td>\n",
       "      <td>0.100693</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.015195</td>\n",
       "      <td>0.005634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.025411</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.100673</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>0.035569</td>\n",
       "      <td>0.100693</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.004690</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.005890</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.015196</td>\n",
       "      <td>0.005628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.403434</td>\n",
       "      <td>0.402114</td>\n",
       "      <td>0.403073</td>\n",
       "      <td>0.418408</td>\n",
       "      <td>0.402527</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.402338</td>\n",
       "      <td>0.428602</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.401993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404431</td>\n",
       "      <td>0.402025</td>\n",
       "      <td>0.402042</td>\n",
       "      <td>0.402042</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.402896</td>\n",
       "      <td>0.403434</td>\n",
       "      <td>0.402273</td>\n",
       "      <td>0.401797</td>\n",
       "      <td>0.402765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.022433</td>\n",
       "      <td>0.017890</td>\n",
       "      <td>0.032788</td>\n",
       "      <td>0.035547</td>\n",
       "      <td>0.052112</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>0.034819</td>\n",
       "      <td>0.047770</td>\n",
       "      <td>0.111039</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032361</td>\n",
       "      <td>0.018446</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>0.018216</td>\n",
       "      <td>0.111044</td>\n",
       "      <td>0.018913</td>\n",
       "      <td>0.024162</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.037366</td>\n",
       "      <td>0.016924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.008741  0.006476  0.688781  0.025336  0.023262  0.102780  0.020752   \n",
       "1    0.007363  0.004709  0.025218  0.024389  0.029653  0.101537  0.024451   \n",
       "2    0.151338  0.027289  0.257260  0.163717  0.071086  0.119523  0.386028   \n",
       "3    0.004723  0.003080  0.020329  0.022626  0.018507  0.100265  0.015014   \n",
       "4    0.403434  0.402115  0.403057  0.418408  0.402515  0.500000  0.402329   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "509  0.403437  0.402116  0.403067  0.418416  0.402523  0.500000  0.402335   \n",
       "510  0.007362  0.004758  0.008855  0.025414  0.013355  0.100673  0.009406   \n",
       "511  0.007359  0.004752  0.008857  0.025411  0.013358  0.100673  0.009408   \n",
       "512  0.403434  0.402114  0.403073  0.418408  0.402527  0.500000  0.402338   \n",
       "513  0.022433  0.017890  0.032788  0.035547  0.052112  0.110845  0.034819   \n",
       "\n",
       "           7         8         9   ...        52        53        54  \\\n",
       "0    0.033187  0.102780  0.006569  ...  0.008791  0.007116  0.006513   \n",
       "1    0.035338  0.101476  0.004618  ...  0.008802  0.005516  0.004514   \n",
       "2    0.068080  0.119396  0.026200  ...  0.050460  0.145669  0.026675   \n",
       "3    0.030677  0.100267  0.002954  ...  0.005806  0.003650  0.002973   \n",
       "4    0.428596  0.500000  0.401994  ...  0.404433  0.402025  0.402043   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "509  0.428610  0.500000  0.401995  ...  0.404436  0.402027  0.402044   \n",
       "510  0.035580  0.100693  0.004604  ...  0.010074  0.004983  0.004617   \n",
       "511  0.035569  0.100693  0.004599  ...  0.010069  0.004981  0.004612   \n",
       "512  0.428602  0.500000  0.401993  ...  0.404431  0.402025  0.402042   \n",
       "513  0.047770  0.111039  0.017956  ...  0.032361  0.018446  0.017598   \n",
       "\n",
       "           55        56        57        58        59        60        61  \n",
       "0    0.006537  0.102851  0.007449  0.008036  0.006510  0.010453  0.007052  \n",
       "1    0.004629  0.101543  0.005552  0.006840  0.004851  0.008522  0.006179  \n",
       "2    0.026124  0.119680  0.029328  0.138876  0.028094  0.355439  0.152298  \n",
       "3    0.002995  0.100271  0.003976  0.004725  0.003236  0.005188  0.003972  \n",
       "4    0.402043  0.500000  0.402897  0.403434  0.402274  0.401799  0.402766  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "509  0.402044  0.500000  0.402898  0.403437  0.402275  0.401800  0.402769  \n",
       "510  0.004695  0.100694  0.005897  0.007610  0.004949  0.015195  0.005634  \n",
       "511  0.004690  0.100694  0.005890  0.007607  0.004944  0.015196  0.005628  \n",
       "512  0.402042  0.500000  0.402896  0.403434  0.402273  0.401797  0.402765  \n",
       "513  0.018216  0.111044  0.018913  0.024162  0.017751  0.037366  0.016924  \n",
       "\n",
       "[514 rows x 62 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(prediction_matrix)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fdbe56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./Prediction_output/Dataset2/GMNN2CD_result_data2.csv\", result, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ec6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13868\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data完成\n",
      "(312, 40)\n",
      "(312, 40)\n",
      "accuracy:0.4926,recall:0.8844,precision:0.0138,F1:0.0263\n",
      "roc_auc 0.8823372232589624\n",
      "AUPR 0.02584852957426272\n",
      "roc_auc 0.8823372232589624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13868\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data完成\n",
      "(312, 40)\n",
      "(312, 40)\n",
      "accuracy:0.4926,recall:0.8929,precision:0.0142,F1:0.0270\n",
      "roc_auc 0.8910603784108513\n",
      "AUPR 0.027958427540680345\n",
      "roc_auc 0.8910603784108513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13868\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data完成\n",
      "(312, 40)\n",
      "(312, 40)\n",
      "accuracy:0.4924,recall:0.8717,precision:0.0131,F1:0.0251\n",
      "roc_auc 0.8692472692918649\n",
      "AUPR 0.022795823181624597\n",
      "roc_auc 0.8692472692918649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13868\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data完成\n",
      "(312, 40)\n",
      "(312, 40)\n",
      "accuracy:0.4924,recall:0.8671,precision:0.0126,F1:0.0243\n",
      "roc_auc 0.8645972950295031\n",
      "AUPR 0.021182309261472167\n",
      "roc_auc 0.8645972950295031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13868\\2984293099.py:4: RuntimeWarning: divide by zero encountered in power\n",
      "  degpow = np.power(deg, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data完成\n",
      "(312, 40)\n",
      "(312, 40)\n",
      "accuracy:0.4922,recall:0.8834,precision:0.0129,F1:0.0248\n",
      "roc_auc 0.8811908224205532\n",
      "AUPR 0.024406765070476844\n",
      "roc_auc 0.8811908224205532\n",
      "均值\n",
      "accuracy:0.4925,recall:0.8799,precision:0.0133,F1:0.0255\n",
      "AUC:0.8777,AUPR:0.0242\n",
      "runtime over, now is :\n",
      "2023-09-10 14:06:27\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, len(one_list), split):\n",
    "    test_index = one_list[i:i + split]\n",
    "    new_circrna_disease_matrix = circrna_disease_matrix.copy()\n",
    "    # 抹除已知关系，已知关系指的是A矩阵中值为一的节点\n",
    "    for index in test_index:\n",
    "        new_circrna_disease_matrix[index[0], index[1]] = 0\n",
    "    roc_circrna_disease_matrix = new_circrna_disease_matrix + circrna_disease_matrix\n",
    "    rel_matrix = new_circrna_disease_matrix\n",
    "    circnum = rel_matrix.shape[0]\n",
    "    disnum = rel_matrix.shape[1]\n",
    "\n",
    "    ##############这里需要更改###################\n",
    "    # 计算相似高斯相似矩阵\n",
    "    # make_sim_matrix =GIP(rel_matrix)\n",
    "    # circ_gipsim_matrix, dis_gipsim_matrix = make_sim_matrix.circsimmatrix, make_sim_matrix.dissimmatrix\n",
    "    # circnum = circrna_disease_matrix.shape[0]\n",
    "    # disnum = circrna_disease_matrix.shape[1]\n",
    "    # SC = circ_gipsim_matrix\n",
    "    # SD = dis_gipsim_matrix\n",
    "    # SB = IBNP(circnum, disnum, rel_matrix)\n",
    "    # # print(SB)\n",
    "    # SK = KATZ(SC, SD, rel_matrix)\n",
    "    # S = (SB + SK) / 2\n",
    "\n",
    "    # rel_matrix = rel_matrix[:10][:10]\n",
    "    # roc_circrna_disease_matrix = roc_circrna_disease_matrix[:10][:10]\n",
    "\n",
    "    gdi, ldi, rnafeat, gl, gd = load_data(rel_matrix, args.cuda)\n",
    "    # print(\"gdi\",gdi)\n",
    "    # gdi = torch.tensor(gdi)\n",
    "    # ldi = torch.tensor(ldi)\n",
    "    # rnafeat = torch.tensor(rnafeat)\n",
    "    # gl = torch.tensor(gl)\n",
    "    # gd = torch.tensor(gd)\n",
    "\n",
    "    print(\"load_data完成\")\n",
    "\n",
    "    gnnq = GNNq()\n",
    "    gnnp = GNNp()\n",
    "    if args.cuda:\n",
    "        gnnq = gnnq.cuda()\n",
    "        gnnp = gnnp.cuda()\n",
    "\n",
    "    rel_matrix_tensor = torch.tensor(np.array(rel_matrix).astype(np.float32))\n",
    "    train(gnnq, gnnp, rnafeat, gdi.t(), rel_matrix_tensor, args.epochs, 0.8, i)\n",
    "    gnnq.eval()\n",
    "    gnnp.eval()\n",
    "    yli, _, ydi, _ = gnnp(rel_matrix_tensor)\n",
    "    resi = args.alpha * yli + (1 - args.alpha) * ydi.t()\n",
    "    if args.cuda:\n",
    "        ymat = resi.cpu().detach().numpy()\n",
    "    else:\n",
    "        ymat = resi.detach().numpy()\n",
    "\n",
    "    S = ymat     \n",
    "    prediction_matrix = S\n",
    "\n",
    "     # giống nhau cả 3 methods\n",
    "    aa = prediction_matrix.shape\n",
    "    bb = roc_circrna_disease_matrix.shape\n",
    "    zero_matrix = np.zeros((prediction_matrix.shape[0], prediction_matrix.shape[1]))\n",
    "    print(prediction_matrix.shape)\n",
    "    print(roc_circrna_disease_matrix.shape)\n",
    "\n",
    "    score_matrix_temp = prediction_matrix.copy()\n",
    "    score_matrix = score_matrix_temp + zero_matrix#标签矩阵等于预测矩阵加抹除关系的矩阵\n",
    "    minvalue = np.min(score_matrix)#每列中的最小值\n",
    "    score_matrix[np.where(roc_circrna_disease_matrix == 2)] = minvalue - 20#？\n",
    "    sorted_circrna_disease_matrix, sorted_score_matrix, sort_index = sortscore.sort_matrix(score_matrix,roc_circrna_disease_matrix)\n",
    "\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    accuracy_list = []\n",
    "    F1_list = []\n",
    "    for cutoff in range(sorted_circrna_disease_matrix.shape[0]):\n",
    "        P_matrix = sorted_circrna_disease_matrix[0:cutoff + 1, :]\n",
    "        N_matrix = sorted_circrna_disease_matrix[cutoff + 1:sorted_circrna_disease_matrix.shape[0] + 1, :]\n",
    "        TP = np.sum(P_matrix == 1)\n",
    "        FP = np.sum(P_matrix == 0)\n",
    "        TN = np.sum(N_matrix == 0)\n",
    "        FN = np.sum(N_matrix == 1)\n",
    "        tpr = TP / (TP + FN)\n",
    "        fpr = FP / (FP + TN)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "        recall = TP / (TP + FN)\n",
    "        precision = TP / (TP + FP)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "        F1 = (2 * TP) / (2*TP + FP + FN)\n",
    "        if (2*TP + FP + FN)==0 :\n",
    "            F1 = 0\n",
    "        F1_list.append(F1)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    # 下面是对top50，top100，top200的预测准确的计数\n",
    "    # top_list = [50, 100, 200]\n",
    "    # for num in top_list:\n",
    "    #     P_matrix = sorted_circrna_disease_matrix[0:num, :]\n",
    "    #     N_matrix = sorted_circrna_disease_matrix[num:sorted_circrna_disease_matrix.shape[0] + 1, :]\n",
    "    #     top_count = np.sum(P_matrix == 1)\n",
    "    #     print(\"top\" + str(num) + \": \" + str(top_count))\n",
    "\n",
    "    ################分割线################\n",
    "    tpr_arr_epoch = np.array(tpr_list)\n",
    "    fpr_arr_epoch = np.array(fpr_list)\n",
    "    recall_arr_epoch = np.array(recall_list)\n",
    "    precision_arr_epoch = np.array(precision_list)\n",
    "    accuracy_arr_epoch = np.array(accuracy_list)\n",
    "    F1_arr_epoch = np.array(F1_list)\n",
    "    # print(\"epoch,\",epoch)\n",
    "    print(\"accuracy:%.4f,recall:%.4f,precision:%.4f,F1:%.4f\" % (\n",
    "        np.mean(accuracy_arr_epoch), np.mean(recall_arr_epoch), np.mean(precision_arr_epoch),\n",
    "        np.mean(F1_arr_epoch)))\n",
    "    print(\"roc_auc\", np.trapz(tpr_arr_epoch, fpr_arr_epoch))\n",
    "    print(\"AUPR\", np.trapz(precision_arr_epoch, recall_arr_epoch))\n",
    "\n",
    "    # print(\"TP=%d, FP=%d, TN=%d, FN=%d\" % (TP, FP, TN, FN))\n",
    "    print(\"roc_auc\", np.trapz(tpr_arr_epoch, fpr_arr_epoch))\n",
    "    ##############分割线######################\n",
    "\n",
    "    all_tpr.append(tpr_list)\n",
    "    all_fpr.append(fpr_list)\n",
    "    all_recall.append(recall_list)\n",
    "    all_precision.append(precision_list)\n",
    "    all_accuracy.append(accuracy_list)\n",
    "    all_F1.append(F1_list)\n",
    "\n",
    "tpr_arr = np.array(all_tpr)\n",
    "fpr_arr = np.array(all_fpr)\n",
    "recall_arr = np.array(all_recall)\n",
    "precision_arr = np.array(all_precision)\n",
    "accuracy_arr = np.array(all_accuracy)\n",
    "F1_arr = np.array(all_F1)\n",
    "\n",
    "mean_cross_tpr = np.mean(tpr_arr, axis=0)  # axis=0\n",
    "mean_cross_fpr = np.mean(fpr_arr, axis=0)\n",
    "mean_cross_recall = np.mean(recall_arr, axis=0)\n",
    "mean_cross_precision = np.mean(precision_arr, axis=0)\n",
    "mean_cross_accuracy = np.mean(accuracy_arr, axis=0)\n",
    "# 计算此次五折的平均评价指标数值\n",
    "mean_accuracy = np.mean(np.mean(accuracy_arr, axis=1), axis=0)\n",
    "mean_recall = np.mean(np.mean(recall_arr, axis=1), axis=0)\n",
    "mean_precision = np.mean(np.mean(precision_arr, axis=1), axis=0)\n",
    "mean_F1 = np.mean(np.mean(F1_arr, axis=1), axis=0)\n",
    "print(\"均值\")\n",
    "print(\"accuracy:%.4f,recall:%.4f,precision:%.4f,F1:%.4f\"%(mean_accuracy, mean_recall, mean_precision, mean_F1))\n",
    "\n",
    "roc_auc = np.trapz(mean_cross_tpr, mean_cross_fpr)\n",
    "AUPR = np.trapz(mean_cross_precision, mean_cross_recall)\n",
    "\n",
    "print(\"AUC:%.4f,AUPR:%.4f\"%(roc_auc, AUPR))\n",
    "\n",
    "# disease-circRNA\n",
    "\n",
    "# GMNN2CD_circRNA_cancer_5fold_AUC\n",
    "# GMNN2CD_circRNA_cancer_5fold_AUPR\n",
    "\n",
    "# circRNADisease\n",
    "\n",
    "# with h5py.File('./Data/circ2Traits/circRNA_disease.h5','r') as hf:\n",
    "#     circrna_disease_matrix = hf['infor'][:]\n",
    "\n",
    "# circad\n",
    "# with h5py.File('./Data/circad/circrna_disease.h5', 'r') as hf:\n",
    "#     circrna_disease_matrix = hf['infor'][:]\n",
    "# 存储tpr，fpr,recall,precision\n",
    "with h5py.File('./PlotFigure/GMNN2CD_circRNADisease_10fold_AUC.h5','w') as hf:\n",
    "    hf['fpr'] = mean_cross_fpr\n",
    "    hf['tpr'] = mean_cross_tpr\n",
    "with h5py.File('./PlotFigure/GMNN2CD_circRNADisease_10fold_AUPR.h5','w') as h:\n",
    "    h['recall'] = mean_cross_recall\n",
    "    h['precision'] = mean_cross_precision\n",
    "\n",
    "plt.plot(mean_cross_fpr, mean_cross_tpr, label='mean ROC=%0.4f' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=0)\n",
    "plt.savefig(\"./FinalResultPng/roc-circRNADisease_10fold.png\")\n",
    "print(\"runtime over, now is :\")\n",
    "print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ad8930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = pd.DataFrame(prediction_matrix)\n",
    "np.savetxt(\"GMNN2CD_result_2.csv\", result, delimiter=\",\")\n",
    "gmnn_matrix = np.genfromtxt('GMNN2CD_result.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d96774db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "are_equal = np.array_equal(prediction_matrix, gmnn_matrix)\n",
    "are_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26929e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.848806</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100236</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.031621</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.029773</td>\n",
       "      <td>0.025781</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.002963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074503</td>\n",
       "      <td>0.773502</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.008662</td>\n",
       "      <td>0.041661</td>\n",
       "      <td>0.005230</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101279</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.030954</td>\n",
       "      <td>0.030467</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.004681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404963</td>\n",
       "      <td>0.403266</td>\n",
       "      <td>0.402185</td>\n",
       "      <td>0.403606</td>\n",
       "      <td>0.402849</td>\n",
       "      <td>0.401913</td>\n",
       "      <td>0.402475</td>\n",
       "      <td>0.402488</td>\n",
       "      <td>0.401608</td>\n",
       "      <td>0.402446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.401667</td>\n",
       "      <td>0.425791</td>\n",
       "      <td>0.403426</td>\n",
       "      <td>0.401995</td>\n",
       "      <td>0.401995</td>\n",
       "      <td>0.403606</td>\n",
       "      <td>0.402446</td>\n",
       "      <td>0.401633</td>\n",
       "      <td>0.402089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.848544</td>\n",
       "      <td>0.051125</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.036096</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100236</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.031580</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.029671</td>\n",
       "      <td>0.025680</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.002952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.848785</td>\n",
       "      <td>0.051314</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100236</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.029769</td>\n",
       "      <td>0.025778</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.091363</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.008837</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100597</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.033133</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>0.763312</td>\n",
       "      <td>0.029854</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.004536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.867440</td>\n",
       "      <td>0.050063</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.035244</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.031263</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.025153</td>\n",
       "      <td>0.024894</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.848662</td>\n",
       "      <td>0.051221</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.036166</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100236</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.031570</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.029720</td>\n",
       "      <td>0.025728</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.002955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.030177</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>0.008928</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.011975</td>\n",
       "      <td>0.022537</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100230</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>0.034298</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.019780</td>\n",
       "      <td>0.019781</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>0.004898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.050436</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.035534</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100053</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.026823</td>\n",
       "      <td>0.025150</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.002695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.848806  0.051330  0.002191  0.002880  0.002582  0.003825  0.036242   \n",
       "1    0.074503  0.773502  0.004632  0.007082  0.005299  0.008662  0.041661   \n",
       "2    0.404963  0.403266  0.402185  0.403606  0.402849  0.401913  0.402475   \n",
       "3    0.848544  0.051125  0.002190  0.002877  0.002580  0.003820  0.036096   \n",
       "4    0.848785  0.051314  0.002193  0.002882  0.002584  0.003827  0.036232   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "307  0.091363  0.043739  0.005725  0.005998  0.006372  0.008837  0.036527   \n",
       "308  0.867440  0.050063  0.001507  0.002381  0.001877  0.003167  0.035244   \n",
       "309  0.848662  0.051221  0.002189  0.002877  0.002579  0.003821  0.036166   \n",
       "310  0.030177  0.024810  0.008928  0.010428  0.010079  0.011975  0.022537   \n",
       "311  0.859079  0.050436  0.001686  0.002506  0.002063  0.003341  0.035534   \n",
       "\n",
       "           7         8         9   ...        30        31        32  \\\n",
       "0    0.003437  0.002398  0.003077  ...  0.100236  0.002465  0.031621   \n",
       "1    0.005230  0.004052  0.004786  ...  0.101279  0.004187  0.033520   \n",
       "2    0.402488  0.401608  0.402446  ...  0.500000  0.401667  0.425791   \n",
       "3    0.003424  0.002389  0.003068  ...  0.100236  0.002455  0.031580   \n",
       "4    0.003438  0.002399  0.003081  ...  0.100236  0.002465  0.031609   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "307  0.005100  0.003831  0.004664  ...  0.100597  0.003925  0.033133   \n",
       "308  0.003081  0.002042  0.002683  ...  0.100002  0.002111  0.031263   \n",
       "309  0.003428  0.002391  0.003071  ...  0.100236  0.002458  0.031570   \n",
       "310  0.005576  0.004014  0.005451  ...  0.100230  0.004130  0.034298   \n",
       "311  0.003165  0.002125  0.002776  ...  0.100053  0.002194  0.031356   \n",
       "\n",
       "           33        34        35        36        37        38        39  \n",
       "0    0.004500  0.029773  0.025781  0.002954  0.003063  0.002393  0.002963  \n",
       "1    0.006408  0.030954  0.030467  0.005947  0.005393  0.004052  0.004681  \n",
       "2    0.403426  0.401995  0.401995  0.403606  0.402446  0.401633  0.402089  \n",
       "3    0.004484  0.029671  0.025680  0.002951  0.003054  0.002384  0.002952  \n",
       "4    0.004501  0.029769  0.025778  0.002956  0.003068  0.002394  0.002964  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "307  0.006395  0.763312  0.029854  0.006169  0.004952  0.003793  0.004536  \n",
       "308  0.004172  0.025153  0.024894  0.002383  0.002683  0.002071  0.002614  \n",
       "309  0.004489  0.029720  0.025728  0.002951  0.003058  0.002386  0.002955  \n",
       "310  0.007124  0.019780  0.019781  0.010673  0.005109  0.004053  0.004898  \n",
       "311  0.004248  0.026823  0.025150  0.002529  0.002772  0.002145  0.002695  \n",
       "\n",
       "[312 rows x 40 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d743f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e9c9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tuple = (np.where(circrna_disease_matrix == 1))\n",
    "one_list = list(zip(index_tuple[0], index_tuple[1]))\n",
    "random.shuffle(one_list)\n",
    "split = math.ceil(len(one_list) / 5)\n",
    "\n",
    "all_tpr = []\n",
    "all_fpr = []\n",
    "all_recall = []\n",
    "all_precision = []\n",
    "all_accuracy = []\n",
    "all_F1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bb0820c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850357</td>\n",
       "      <td>0.050124</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.017010</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.100335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082882</td>\n",
       "      <td>0.754782</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.033245</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.012039</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.103281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850059</td>\n",
       "      <td>0.049845</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.100335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.851377</td>\n",
       "      <td>0.050990</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.017388</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.100335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.850246</td>\n",
       "      <td>0.050020</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.016971</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>0.016979</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.100335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.046497</td>\n",
       "      <td>0.027164</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.016319</td>\n",
       "      <td>0.024130</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.782960</td>\n",
       "      <td>0.015872</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.100312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.870136</td>\n",
       "      <td>0.048707</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.011197</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.100014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.850577</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.017091</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.017049</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.100335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.014440</td>\n",
       "      <td>0.014040</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.017095</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.017102</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.100026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.859790</td>\n",
       "      <td>0.049555</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.016401</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.100125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.850357  0.050124  0.003923  0.003390  0.002835  0.003781  0.017021   \n",
       "1    0.082882  0.754782  0.010922  0.011202  0.008810  0.014577  0.033245   \n",
       "2    0.850059  0.049845  0.003909  0.003378  0.002825  0.003757  0.016885   \n",
       "3    0.851377  0.050990  0.003951  0.003414  0.002851  0.003837  0.017388   \n",
       "4    0.850246  0.050020  0.003919  0.003386  0.002829  0.003773  0.016971   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "307  0.046497  0.027164  0.008352  0.005925  0.003620  0.016319  0.024130   \n",
       "308  0.870136  0.048707  0.003121  0.002785  0.002071  0.002954  0.015787   \n",
       "309  0.850577  0.050300  0.003932  0.003398  0.002839  0.003793  0.017091   \n",
       "310  0.014440  0.014040  0.010035  0.006815  0.002790  0.017095  0.015823   \n",
       "311  0.859790  0.049555  0.003440  0.003020  0.002368  0.003291  0.016401   \n",
       "\n",
       "           7         8         9   ...        30        31        32  \\\n",
       "0    0.002979  0.002978  0.002986  ...  0.003297  0.002774  0.002771   \n",
       "1    0.006892  0.006836  0.007058  ...  0.007796  0.007210  0.007222   \n",
       "2    0.002968  0.002967  0.002974  ...  0.003284  0.002762  0.002759   \n",
       "3    0.002997  0.002997  0.003004  ...  0.003319  0.002792  0.002789   \n",
       "4    0.002973  0.002972  0.002980  ...  0.003291  0.002768  0.002765   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "307  0.003634  0.003629  0.003615  ...  0.004087  0.003464  0.003440   \n",
       "308  0.002480  0.002480  0.002480  ...  0.003008  0.002472  0.002466   \n",
       "309  0.002984  0.002983  0.002991  ...  0.003303  0.002779  0.002776   \n",
       "310  0.003279  0.003279  0.003282  ...  0.003908  0.003256  0.003249   \n",
       "311  0.002668  0.002668  0.002671  ...  0.003115  0.002583  0.002578   \n",
       "\n",
       "           33        34        35        36        37        38        39  \n",
       "0    0.003759  0.017010  0.003949  0.004202  0.003618  0.003120  0.100335  \n",
       "1    0.008914  0.022906  0.012039  0.011240  0.009394  0.007096  0.103281  \n",
       "2    0.003742  0.016924  0.003924  0.004189  0.003601  0.003110  0.100335  \n",
       "3    0.003782  0.017224  0.004004  0.004230  0.003641  0.003137  0.100335  \n",
       "4    0.003747  0.016979  0.003941  0.004198  0.003606  0.003115  0.100335  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "307  0.004504  0.782960  0.015872  0.006439  0.004210  0.004134  0.100312  \n",
       "308  0.003207  0.011197  0.002969  0.003479  0.003197  0.002693  0.100014  \n",
       "309  0.003763  0.017049  0.003960  0.004212  0.003622  0.003126  0.100335  \n",
       "310  0.003898  0.024055  0.017102  0.007286  0.003906  0.004061  0.100026  \n",
       "311  0.003420  0.014002  0.003372  0.003765  0.003357  0.002852  0.100125  \n",
       "\n",
       "[312 rows x 40 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25d944e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312, 40)\n",
      "(312, 40)\n"
     ]
    }
   ],
   "source": [
    "aa = prediction_matrix.shape\n",
    "bb = roc_circrna_disease_matrix.shape\n",
    "zero_matrix = np.zeros((prediction_matrix.shape[0], prediction_matrix.shape[1]))\n",
    "print(prediction_matrix.shape)\n",
    "print(roc_circrna_disease_matrix.shape)\n",
    "\n",
    "score_matrix_temp = prediction_matrix.copy()\n",
    "score_matrix = score_matrix_temp + zero_matrix\n",
    "minvalue = np.min(score_matrix)\n",
    "score_matrix[np.where(roc_circrna_disease_matrix == 2)] = minvalue - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9effef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018637559842318296"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minvalue.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b453d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "0\n",
      "12149\n",
      "99\n",
      "True Positive Rate (TPR): 0.7009063444108762\n",
      "False Positive Rate (FPR): 0.0\n"
     ]
    }
   ],
   "source": [
    "P_matrix = np.where(prediction_matrix >= 0.50001, 1, 0)  \n",
    "TP = np.sum(np.logical_and(P_matrix == 1, circrna_disease_matrix == 1))\n",
    "FP = np.sum(np.logical_and(P_matrix == 1, circrna_disease_matrix == 0))\n",
    "TN = np.sum(np.logical_and(P_matrix == 0, circrna_disease_matrix == 0))\n",
    "FN = np.sum(np.logical_and(P_matrix == 0, circrna_disease_matrix == 1))\n",
    "\n",
    "# Tính True Positive Rate (TPR) và False Positive Rate (FPR)\n",
    "tpr = TP / (TP + FN)\n",
    "fpr = FP / (FP + TN)\n",
    "\n",
    "print(TP) \n",
    "print(FP)  \n",
    "print(TN)  \n",
    "print(FN)  \n",
    "print(\"True Positive Rate (TPR):\", tpr)\n",
    "print(\"False Positive Rate (FPR):\", fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "856eeabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_matrix_df = pd.DataFrame(P_matrix)\n",
    "sum_of_values = P_matrix_df.sum().sum()\n",
    "sum_of_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9ff3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"GMNN2CD_test.csv\", P_matrix, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372e4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
